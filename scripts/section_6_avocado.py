#!/usr/bin/env python
# coding: utf-8

# # Avocado Pricing and Supply Using Mathematical Optimization
# 
# **Goal**: Develop a data-science and decision-making pipeline for pricing and distribution of avocados to maximize revenue.
# 
# To accomplish this, the notebook will walk trough three stages:
# 
# 1. A quick review of [Hass Avocado Board](https://hassavocadoboard.com/) (HAB) data
# 2. A prediction model for avocado demand as a function of price, region, year and seasonality.
# 3. An optimization model that sets the optimal price and supply quantity to maximize the net revenue while incorporating transportation and costs.
# 
# See also: [How Much Is Too Much? Avocado Pricing and Supply Using Mathematical Optimization](https://github.com/Gurobi/modeling-examples/tree/master/price_optimization)

# ## Load the Packages and Prepare the Dataset
# 
# The dataset from HAB contains sales data for the years 2019-2022. This data is augmented by a previous download from HAB available on [Kaggle](https://www.kaggle.com/datasets/timmate/avocado-prices-2020) with sales for the years 2015-2018.
# 
# One of the regions in the above data frame is `Total_US`, so we can create a list of regions, excluding the total, which can be used to subset the data now. It'll be used later in the example as well.

###############################################################################
# Questions to consider
###############################################################################

# If the optimization model has to choose peak=0 or peak=1, should I
# learn just wrt to the peak or off-peak data? Should I plot just the
# peak or off-peak data?

# Gurobi added non-trivial lower and upper bounds on x_r. Should I
# remove these bounds? Yes, I have done so on 2024-04-19. Does not seem
# to make any difference

# We currently set totaly supply B = 30. Is this a reasonable value?

# Should we do everything wrt (p,x,d), not just (p,d)?

# Should we show the x values in the paper? Do they carry much meaning?

# CH and CH^+ are taken wrt to all price data, regardless of peak or
# off-peak, right?

###############################################################################
# STAGE 0 --- License and packages
###############################################################################

# Set the parameters for the Gurobi license

# This is Sam's floating license

params = {
    "WLSACCESSID": '1c31e7ee-6025-4b2e-a5a0-1ac137f87660',
    "WLSSECRET": 'dd7feb58-13dd-4150-995d-4aff2fa9d0b8',
    "LICENSEID": 2439168
}

# Import all the packages that we need

import pandas as pd
import warnings
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split

from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.compose import make_column_transformer

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import cross_val_score
from sklearn.pipeline import make_pipeline
from sklearn.metrics import r2_score

# pip install gurobipy_pandas # this also installs gurobipy
# pip install gurobi-machinelearning
import gurobipy as gp
import gurobipy_pandas as gppd
from gurobi_ml import add_predictor_constr
from sklearn.ensemble import GradientBoostingRegressor

###############################################################################
# STAGE 1 --- Data import and preparation
###############################################################################

# Get the data hosted by Gurobi

data_url = "https://raw.githubusercontent.com/Gurobi/modeling-examples/master/price_optimization/"
avocado = pd.read_csv(data_url+"HAB_data_2015to2022.csv")
avocado["date"] = pd.to_datetime(avocado["date"])
avocado = avocado.sort_values(by = "date")

# Specify the list of regions that we wish to keep. This will enable us
# to exclude Total_US

regions = [
    "Great_Lakes",
    "Midsouth",
    "Northeast",
    "Northern_New_England",
    "SouthCentral",
    "Southeast",
    "West",
    "Plains"
]

# Keep only the regions we want to keep

df = avocado[(avocado.region.isin(regions))] # & (avocado.peak==0)

# Drop the date column. We will just need the year column

df.drop(columns=['date']) #,'peak'

###############################################################################
# STAGE 2 --- Basic summary statistics and plot
###############################################################################

# Calculate some statistics for the paper. Would be good to document this

tmp = df
tmp['revenue'] = tmp['units_sold'] * tmp['price']
aggregated_tmp = tmp.groupby('date').sum()
aggregated_tmp['price'] = aggregated_tmp['price'] / 8
#  print(aggregated_tmp.sort_values(by='date'))
print(tmp[['units_sold', 'price', 'revenue']].mean())
print(aggregated_tmp[['units_sold', 'price', 'revenue']].mean())

tmp = df[df['peak'] == 0]
tmp['revenue'] = tmp['units_sold'] * tmp['price']
aggregated_tmp = tmp.groupby('date').sum()
aggregated_tmp['price'] = aggregated_tmp['price'] / 8
#  print(aggregated_tmp.sort_values(by='date'))
print(tmp[['units_sold', 'price', 'revenue']].mean())
print(aggregated_tmp[['units_sold', 'price', 'revenue']].mean())

# Create a scatterplot of all data. Will we include this in the paper?
# Not sure

plt.figure(figsize=(10, 6))
r_plt = sns.scatterplot(data=df, x='price', y='units_sold', hue='region')
r_plt.legend(fontsize = 12)
r_plt.set_xlabel('Price', fontsize = 16)
r_plt.set_ylabel('Units Sold', fontsize = 16)
#  plt.savefig('../results/figures/avocado_data_scatterplot.png', dpi = 150, bbox_inches = 'tight')
# plt.show()

###############################################################################
# STAGE 3 --- Learn demand model
###############################################################################

# ## Predict and Visualize the Sales
# 
# In the first instance of this example, further analysis was done on
# the input data along with a few visualizations. Here, we will go
# directly to the predicive model training, starting with a random split
# of the dataset into $70\%$ training and $30\%$ testing data.
#
# Note that the region is a categorical variable and we will transform
# that variable using Scikit Learn's `OneHotEncoder`. We also use a
# standard scaler for prices and year index, combining all of the ese
# with `Column Transformer` built using `make_column_transformer`.
# 
# The regression model is a pipeline consisting of the `Column Transformer` and the type of model we want to use for the regression. For comparison, we'll stick with a linear regression.
# 
# We can observe a good $R^2$ value in the test set. We will now train the fit to the full dataset.

X = df[["region", "price", "year", "peak"]]
y = df["units_sold"]

# Split the data for training and testing
X_train, X_test, y_train, y_test = train_test_split(
    X, y, train_size = 0.7, random_state = 1
)

feat_transform = make_column_transformer(
    (OneHotEncoder(drop="first"), ["region"]),
    (StandardScaler(), ["price", "year"]),
    ("passthrough", ["peak"]),
    verbose_feature_names_out=False,
    remainder='drop'
)

#  reg = make_pipeline(feat_transform, LinearRegression())
#  scores = cross_val_score(reg, X_train, y_train, cv=5)
#  #  print("%0.4f R^2 with a standard deviation of %0.4f" % (scores.mean(), scores.std()))
#  # Find model score on test data
#  reg.fit(X_train, y_train)
#  y_pred = reg.predict(X_test)
#  #  print(f"The R^2 value in the test set is {np.round(r2_score(y_test, y_pred),5)}")
#  reg.fit(X, y)
#  y_pred_full = reg.predict(X)
#  #  print(f"The R^2 value in the full dataset is {np.round(r2_score(y, y_pred_full),5)}")

reg = make_pipeline(feat_transform, GradientBoostingRegressor(n_estimators=100, max_leaf_nodes = 20,
                                              loss = 'absolute_error', random_state = 123))
scores = cross_val_score(reg, X_train, y_train, cv=5)
#  print("%0.4f R^2 with a standard deviation of %0.4f" % (scores.mean(), scores.std()))
# Fit to entire training data
reg.fit(X_train, y_train)
y_pred = reg.predict(X_test)
#  print(f"The R^2 value in the test set is {np.round(r2_score(y_test, y_pred),5)}")
reg.fit(X, y)
y_pred_full = reg.predict(X)
#  print(f"The R^2 value in the full dataset is {np.round(r2_score(y, y_pred_full),5)}")

###############################################################################
# STAGE 4 --- Define parameters and data structures needed for optimization
###############################################################################

# Because we are optimizing for a specific year and a specific
# seasonality (peak vs off-peak), we need to specify the values of year
# and peak

year = 2023
peak_or_not = 0

# ## Optimize for Price and Supply of Avocados
# 
# Here is a quick review of notation for the formulation of the
# mathematical optimization model. The subscript $r$ will be used to
# denote each region.
#
# ### Input parameters
#
# - $d(p,r)$: predicted demand in region $r$ when the avocado price is $p$
# - $B$: available avocados to be distributed across the regions
# - $c_{waste}$: cost ($\$$) per wasted avocado
# - $c^r_{transport}$: cost ($\$$) of transporting a avocado to region $r$
# - $a_{min},a_{max}$: minimum and maximum price ($\$$) per avocado
# - $b^r_{min},b^r_{max}$: minimum and maximum number of avocados allocated to region $r$
# 
# The following code sets values for these parameters. Feel free to
# adjust these to see how the solution to the optimization model will
# change.
# 
# ### Create dataframe for the fixed features of the regression
# 
# We now start creating the input of the regression in the optimization
# models with the features that are fixed and use `gurobipy-pandas` that
# help to more easily create gurobipy models using pandas data.
#
# First, create a dataframe with the features that are fixed in our
# optimization problem. It is indexed by the regions (we want to use
# one regression to predict demand for all regions) and has the three
# columns corresponding to the fixed features:
# 
# * `year`
# * `peak` with the value of `peak_or_not`
# * `region` that repeats the names of the regions.
# 
# Let's display the dataframe to make sure it is correct.

# Setup the parameters of the model (not including the demand function
# itself)

B = 30.0        # total amount of avocado supply
c_waste = 0.1 # the cost ($) of wasting an avocado

# the cost of transporting an avocado
c_transport = pd.Series(
    {
        "Great_Lakes": 0.3,
        "Midsouth": 0.1,
        "Northeast": 0.4,
        "Northern_New_England": 0.5,
        "SouthCentral": 0.3,
        "Southeast": 0.2,
        "West": 0.2,
        "Plains": 0.2,
    }, name='transport_cost'
)
c_transport = c_transport.loc[regions]

a_min = 0.6  # minimum avocado price # Gurobi originally had 0
a_max = 2.0  # maximum avocado price

# Get the lower and upper bounds from the dataset for the price and the
# number of products to be stocked

data = pd.concat([c_transport,
                  df.groupby("region")["units_sold"].min().rename('min_delivery'),
                  df.groupby("region")["units_sold"].max().rename('max_delivery'),
                  df.groupby("region")["price"].max().rename('max_price'),
                                   df.groupby("region")["price"].min().rename('min_price')], axis=1)

feats = pd.DataFrame(
    data={
        "year": year,
        "peak": peak_or_not,
        "region": regions,
    },
    index=regions
)

# ### Decision Variables
# 
# Let us now define the decision variables. In our model, we want to
# store the price and number of avocados allocated to each region. We
# also want variables that track how many avocados are predicted to be
# sold and how many are predicted to be wasted. The following notation
# is used to model these decision variables.
# 
# - $p$ the price of an avocado ($\$$) in each region
# - $x$ the number of avocados supplied to each region
# - $s$ the predicted number of avocados sold in each region
# - $u$ the predicted number of avocados unsold (wasted) in each region
# - $d$ the predicted demand in each region
# 
# All those variables are created using gurobipy-pandas, with the
# function `gppd.add_vars` they are given the same index as the `data`
# dataframe.
# 
# ### Add the Supply Constraint
# 
# We now introduce the constraints. The first constraint is to make sure
# that the total number of avocados supplied is equal to $B$, which can
# be mathematically expressed as follows.
# 
# \begin{align*} \sum_{r} x_r &= B \end{align*}
# 
# ### Add Constraints That Define Sales Quantity
# 
# As a quick reminder, the sales quantity is the minimum of the
# allocated quantity and the predicted demand, i.e., $s_r = \min
# \{x_r,d_r(p_r)\}$ This relationship can be modeled by the following two
# constraints for each region $r$.
# 
# \begin{align*} s_r &\leq x_r  \\
# s_r &\leq d(p_r,r) \end{align*}
# 
# In this case, we use gurobipy-pandas `add_constrs` function, which is
# intuitive to use given the inequalities above.
# 
# ### Add the Wastage Constraints
# 
# Finally, we should define the predicted unsold number of avocados in
# ach region, given by the supplied quantity that is not predicted to be
# sold. We can express this mathematically for each region $r$.
# 
# \begin{align*} u_r &= x_r - s_r \end{align*}
# 
# ### Add the constraints to predict demand
#
# First, we create our full input for the predictor constraint. We
# concatenate the `p` variables and the fixed features. Remember that
# the predicted price is a function of region, year, and peak/off-peak
# season.
# 
# Now, we just call
# [add_predictor_constr](https://gurobi-machinelearning.readthedocs.io/en/stable/api/AbstractPredictorConstr.html#gurobi_ml.add_predictor_constr)
# to insert the constraints linking the features and the demand into the model `m`.
# 
# It is important that you keep the columns in the order above, otherwise you will see an error. The columns must be in the same order as the training data.
# 
# ### Set the Objective
# 
# The goal is to maximize the **net revenue**, which is the product of price and quantity, minus costs over all regions. This model assumes the purchase costs are fixed (since the amount $B$ is fixed) and are therefore not incorporated.
# 
# Using the defined decision variables, the objective can be written as follows.
# 
# \begin{align} \textrm{maximize} &  \sum_{r}  (p_r * s_r - c_{waste} * u_r -
# c^r_{transport} * x_r)& \end{align}
# 
# ### Fire Up the Solver
# 
# In our model, the objective is **quadratic** since we take the product of price
# and the predicted sales, both of which are variables. Maximizing a quadratic
# term is said to be **non-convex**, and we specify this by setting the value of
# the [Gurobi NonConvex
# parameter](https://www.gurobi.com/documentation/10.0/refman/nonconvex.html) to be
# $2$.
# 
# 
# The solver solved the optimization problem in less than a second. Let us now
# analyze the optimal solution by storing it in a Pandas dataframe.
# 
# We can also check the error in the estimate of the Gurobi solution for the regression model.

###############################################################################
# STAGE 5 --- Build and solve the optimization models
###############################################################################

#------------------------------------------------------------------------------
# Gurobi's default
#------------------------------------------------------------------------------

env = gp.Env()
#  env = gp.Env(params = params) # To enable Sam's floating license

m = gp.Model("Avocado_Price_Allocation", env = env)
m.Params.NonConvex = 2
m.Params.LogToConsole = 0
m.Params.TimeLimit = 600

p = gppd.add_vars(m, data, name = "price", lb = a_min, ub = a_max)
#  x = gppd.add_vars(m, data, name = "x", lb = 'min_delivery', ub = 'max_delivery')
x = gppd.add_vars(m, data, name = "x", lb = 0)
s = gppd.add_vars(m, data, name = "s")
u = gppd.add_vars(m, data, name = "w")
d = gppd.add_vars(m, data, lb = -gp.GRB.INFINITY, name="demand")

m.setObjective((p * s).sum() - c_waste * u.sum() - (c_transport * x).sum(),
               gp.GRB.MAXIMIZE)

m.addConstr(x.sum() == B)
gppd.add_constrs(m, s, gp.GRB.LESS_EQUAL, x)
gppd.add_constrs(m, s, gp.GRB.LESS_EQUAL, d)
gppd.add_constrs(m, u, gp.GRB.EQUAL, x - s)

m_feats = pd.concat([feats, p], axis=1)[["region", "price", "year", "peak"]]

m.update()
#  print(m_feats)
#  print("\n\n\n\n\n\n")

pred_constr = add_predictor_constr(m, reg, m_feats, d)

m.optimize()

solution = pd.DataFrame(index=regions)

solution["Price"] = p.gppd.X
solution["Historical_Max"] = data.max_price
solution["Allocated"] = x.gppd.X
solution["Sold"] = s.gppd.X
solution["Wasted"] = u.gppd.X
solution["Pred_demand"] = d.gppd.X

soln_gur = solution

opt_revenue = m.ObjVal
print("\nThe optimal profit: $%f million\n" % opt_revenue)
print(solution.round(3))

#------------------------------------------------------------------------------
# Box
#------------------------------------------------------------------------------

gppd.add_constrs(m, p, gp.GRB.LESS_EQUAL, data['max_price'].values)
gppd.add_constrs(m, p, gp.GRB.GREATER_EQUAL, data['min_price'].values)

m.optimize()

solution = pd.DataFrame(index=regions)

solution["Price"] = p.gppd.X
solution["Historical_Max"] = data.max_price
solution["Allocated"] = x.gppd.X
solution["Sold"] = s.gppd.X
solution["Wasted"] = u.gppd.X
solution["Pred_demand"] = d.gppd.X

soln_box = solution

opt_revenue = m.ObjVal
print("\nThe optimal profit: $%f million\n" % opt_revenue)
print(solution.round(3))

#  print_graphs_primary()

#------------------------------------------------------------------------------
# CH
#------------------------------------------------------------------------------

# Recode the 378 and 8! They should not be hard-coded

mu = m.addMVar(shape=(378), name='mu', lb = 0, ub = 1)
diff_p = gppd.add_vars(m, data, name = "diff_p", lb = -np.inf, ub = np.inf)
m.addConstr(mu.sum() == 1.0)
X_pivot = df.pivot(index='date', columns='region', values='price').loc[:,regions]
m.addConstrs(diff_p.values[i] == p.values[i] - (mu@X_pivot.values)[i] for i in range(8))
eps = 0.0 # Note that eps is currently zero! 
m.addConstr((diff_p * diff_p).sum() <= eps, name = "diff_p_constraint")
m.optimize()

solution = pd.DataFrame(index=regions)
solution["Price"] = p.gppd.X
solution["Historical_Max"] = data.max_price
solution["Allocated"] = x.gppd.X
solution["Sold"] = s.gppd.X
solution["Wasted"] = u.gppd.X
solution["Pred_demand"] = d.gppd.X

soln_ch = solution

opt_revenue = m.ObjVal
print("\nThe optimal profit: $%f million\n" % opt_revenue)
print(solution.round(3))

#------------------------------------------------------------------------------
# CH^+
#------------------------------------------------------------------------------

diff_d = gppd.add_vars(m, data, name = "diff_d", lb = -np.inf, ub = np.inf)
y_pivot = df.pivot(index='date', columns='region', values='units_sold').loc[:,regions]
m.addConstrs(diff_d.values[i] == d.values[i] - (mu@y_pivot.values)[i] for i in range(8))
m.addConstr((diff_d * diff_d).sum() <= eps, name = "diff_d_constraint")
m.optimize()

solution = pd.DataFrame(index=regions)
solution["Price"] = p.gppd.X
solution["Historical_Max"] = data.max_price
solution["Allocated"] = x.gppd.X
solution["Sold"] = s.gppd.X
solution["Wasted"] = u.gppd.X
solution["Pred_demand"] = d.gppd.X

soln_chplus = solution

opt_revenue = m.ObjVal
print("\nThe optimal profit: $%f million\n" % opt_revenue)
print(solution.round(3))

###############################################################################
# STAGE 6 --- Post-process and draw pictures
###############################################################################

def print_graphs_primary():

    #  fig, axs = plt.subplots(4, 2, figsize=(10, 20))
    fig, axs = plt.subplots(4, 2, figsize = (10, 5))

    #  fig.subplots_adjust(wspace=0.4, hspace=0.0)  # You can change these values as needed
    fig.subplots_adjust(hspace=0.0)  # You can change these values as needed

    fig.text(0.05, 0.5, 'Units Sold / Predicted Demand', va='center', ha='center', rotation='vertical', fontsize=16)
    fig.text(0.5, 0.0, 'Price', va='center', ha='center', fontsize=16)

    for k in range(8):

        r = regions[k]
        i = k//2
        j = k%2
        #  X_r = df.loc[(df.region ==r ) & (df.peak == peak_or_not), ["price", "year", "units_sold"]]
        X_r = df.loc[(df.region == r),["price", "year", "units_sold"]]
        x_plt = X_r.price
        #  p_new = np.linspace(.8*min(x_plt),1.2*max(x_plt),50)
        p_new = np.linspace(a_min, a_max, 100)
        x_new = pd.DataFrame(
            data={
                "year": year,
                "peak": peak_or_not,
                "region": r,
                "price": p_new
            },
            index=range(100)
        )
        x_new['units_sold'] = reg.predict(x_new)
        sns.lineplot(data=x_new, x='price', y='units_sold', c='orange', ax=axs[i,j])
        sns.scatterplot(data=X_r, x='price', y='units_sold', legend=0, ax=axs[i,j], c = 'lightsteelblue')
        axs[i, j].legend(title=r, loc='upper right', prop={'size': 3}, handles = [])

        axs[i, j].set_xlabel('')
        axs[i, j].set_ylabel('')
        
        #  plt.tight_layout()

        #  r_plt.legend(fontsize = 12)
        #  plt.savefig('avocado_data_scatterplot.png', dpi = 150, bbox_inches = 'tight')

        #  plt.tight_layout(pad = 1.0)

    #  plt.savefig('../results/figures/avocado_no__opt_soln.png', dpi = 150, bbox_inches = 'tight')

    for k in range(8):
        i = k//2
        j = k%2
        tmp0 = soln_gur.loc[[regions[k]],["Price", "Pred_demand"]]
        sns.scatterplot(data = tmp0, x = 'Price', y = 'Pred_demand', legend = 0, ax = axs[i,j], s = 100)
        axs[i, j].set_xlabel('')
        axs[i, j].set_ylabel('')

    #  plt.savefig('../results/figures/avocado_gur_opt_soln.png', dpi = 150, bbox_inches = 'tight')

    for k in range(8):
        i = k//2
        j = k%2
        tmp1 = soln_box.loc[[regions[k]],["Price", "Pred_demand"]]
        sns.scatterplot(data = tmp1, x = 'Price', y = 'Pred_demand', legend = 0, ax = axs[i,j], s = 100)
        axs[i, j].set_xlabel('')
        axs[i, j].set_ylabel('')

    #  plt.savefig('../results/figures/avocado_box_opt_soln.png', dpi = 150, bbox_inches = 'tight')

    for k in range(8):
        i = k//2
        j = k%2
        tmp2 = soln_ch.loc[[regions[k]],["Price", "Pred_demand"]]
        sns.scatterplot(data = tmp2, x = 'Price', y = 'Pred_demand', legend = 0, ax = axs[i,j], s = 100)
        axs[i, j].set_xlabel('')
        axs[i, j].set_ylabel('')

    #  plt.savefig('../results/figures/avocado_ch__opt_soln.png', dpi = 150, bbox_inches = 'tight')

    for k in range(8):
        i = k//2
        j = k%2
        tmp3 = soln_chplus.loc[[regions[k]],["Price", "Pred_demand"]]
        sns.scatterplot(data = tmp3, x = 'Price', y = 'Pred_demand', legend = 0, ax = axs[i,j], s = 100)
        axs[i, j].set_xlabel('')
        axs[i, j].set_ylabel('')

    plt.savefig('../results/figures/avocado_chp_opt_soln.png', dpi = 150, bbox_inches = 'tight')

    #  plt.show()
        
print_graphs_primary()

#  solution.round(3)


# ## Changing the Regression Model
# Our regression model has some flaws, so let's try another model type and see how the fit produced, and how that will impact the optimization model.
# 
# Most of the optimization model is unchanged given the new regression model. So to update the optimization we `remove` the previous prediction then add the new one just as we did before.
# 
# With the new model created, we can resolve the optimization and extract the new solution
# 
# This was in introductory look at using the Gurobi Machine Learning package. For more on this example, see the [Price Optimization example of Github](https://github.com/Gurobi/modeling-examples/tree/master/price_optimization)
# as well as how to work with the model interactively.
# 
# Copyright © 2023 Gurobi Optimization, LLC

#  reg = make_pipeline(feat_transform, GradientBoostingRegressor(n_estimators=100, max_leaf_nodes = 20,
#                                                loss = 'absolute_error', random_state = 123))
#  scores = cross_val_score(reg, X_train, y_train, cv=5)
#  print("%0.4f R^2 with a standard deviation of %0.4f" % (scores.mean(), scores.std()))
#  # Fit to entire training data
#  reg.fit(X_train, y_train)
#  y_pred = reg.predict(X_test)
#  print(f"The R^2 value in the test set is {np.round(r2_score(y_test, y_pred),5)}")
#  reg.fit(X, y)
#  y_pred_full = reg.predict(X)
#  print(f"The R^2 value in the full dataset is {np.round(r2_score(y, y_pred_full),5)}")
#
#
#  pred_constr.remove()
#  pred_constr = add_predictor_constr(m, reg, m_feats, d)
#  pred_constr.print_stats()
#  m.update()
#
#  m.optimize()
#
#
#  solution = pd.DataFrame(index=regions)
#
#  solution["Price"] = p.gppd.X
#  solution["Max_Price"] = data.max_price
#  solution["Allocated"] = x.gppd.X
#  solution["Sold"] = s.gppd.X
#  solution["Wasted"] = u.gppd.X
#  solution["Pred_demand"] = d.gppd.X
#
#  opt_revenue = m.ObjVal
#  print("\nThe optimal profit: $%f million" % opt_revenue)
#  solution.round(3)
#
#  print_graphs_primary()
#
