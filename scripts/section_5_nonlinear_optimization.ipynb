{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "39c2d36f-5d96-4c87-8d2d-e202e744e878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-01-04\n",
      "iter = 0\n",
      "iter = 5\n",
      "iter = 10\n",
      "iter = 15\n",
      "iter = 20\n",
      "iter = 25\n",
      "iter = 30\n",
      "iter = 35\n",
      "iter = 40\n",
      "iter = 45\n",
      "iter = 50\n",
      "iter = 55\n",
      "iter = 60\n",
      "iter = 65\n",
      "iter = 70\n",
      "iter = 75\n",
      "iter = 80\n",
      "iter = 85\n",
      "iter = 90\n",
      "iter = 95\n",
      "[[1.         1.         1.         1.        ]\n",
      " [0.99437314 0.94442163 0.9350343  0.99437314]\n",
      " [0.48423531 2.32149516 1.04177026 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Import libraries (do we use all of these?)\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import pandas as pd\n",
    "import gurobipy as gp\n",
    "import gurobipy_pandas as gppd\n",
    "from gurobi_ml import add_predictor_constr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import cm\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Set base dimension\n",
    "\n",
    "n1 = 5\n",
    "\n",
    "# Set uniform lower and upper bounds for the domain X\n",
    "\n",
    "L = -1\n",
    "U =  1\n",
    "\n",
    "# Set sample size\n",
    "\n",
    "N = 1000\n",
    "\n",
    "# Setup data structures for errors\n",
    "\n",
    "ove_box    = np.array([])\n",
    "ove_ch     = np.array([])\n",
    "ove_chplus = np.array([])\n",
    "\n",
    "ose_box    = np.array([])\n",
    "ose_ch     = np.array([])\n",
    "ose_chplus = np.array([])\n",
    "\n",
    "fve_box    = np.array([])\n",
    "fve_ch     = np.array([])\n",
    "fve_chplus = np.array([])\n",
    "\n",
    "fe_box    = np.array([])\n",
    "fe_ch     = np.array([])\n",
    "fe_chplus = np.array([])\n",
    "\n",
    "# Initialize optimization environment\n",
    "\n",
    "env = gp.Env()\n",
    "\n",
    "# Loop over iterations\n",
    "\n",
    "for iter in range(100):\n",
    "\n",
    "    if iter % 5 == 0:\n",
    "        print('iter = ' + str(iter))\n",
    "\n",
    "    # Generate random linear objective; quadratic part is currently 0\n",
    "\n",
    "    c = npr.normal(0, 1, [n1, 1])\n",
    "    c = c / np.linalg.norm(c)\n",
    "\n",
    "    # Determine opt sol and val\n",
    "\n",
    "    x_star = -c\n",
    "    v_star = -1\n",
    "\n",
    "    # Generate samples D_N inside and outside of unit ball,\n",
    "    # i.e., not just feasible samples\n",
    "\n",
    "    #D_N = npr.uniform(L, U, (N, n1))\n",
    "    D_N = npr.normal(0, 1, (N, n1))\n",
    "    for j in range(np.shape(D_N)[0]):\n",
    "        vec = D_N[j, ]\n",
    "        vec = vec.flatten()\n",
    "        vec = vec / np.linalg.norm(vec)\n",
    "        vec = (0.5 + npr.uniform(0, 1)) * vec\n",
    "        D_N[j, ] = vec\n",
    "    \n",
    "    # Evaluate function h on D_N (currently with \"5%\" noise)\n",
    "    \n",
    "    h_D_N = np.linalg.norm(D_N, axis = 1)\n",
    "    h_D_N = h_D_N + 0.05 * npr.normal(0, 1, (N))\n",
    "    # print(\"Reset the noise\")\n",
    "    \n",
    "    # Learn function h_hat\n",
    "    \n",
    "    hidden_size = 30\n",
    "    h_hat = MLPRegressor( \\\n",
    "        hidden_layer_sizes = (hidden_size, hidden_size), max_iter = 1000 \\\n",
    "    )\n",
    "    h_hat = h_hat.fit(D_N, h_D_N)\n",
    "\n",
    "    # Initialize optimization model\n",
    "\n",
    "    m = gp.Model(\"trs\", env = env)\n",
    "    m.Params.LogToConsole = 0\n",
    "    m.Params.NonConvex = 2\n",
    "    \n",
    "    # Setup and solve model with Box validity domain\n",
    "    \n",
    "    L_tmp = np.min(D_N, axis = 0)\n",
    "    U_tmp = np.max(D_N, axis = 0)\n",
    "    x = m.addMVar(shape = (n1), name = 'x', lb = L_tmp, ub = U_tmp)\n",
    "    y = m.addVar(name = 'y', ub = 1)\n",
    "    add_predictor_constr(m, h_hat, x, y)\n",
    "    m.setMObjective(None, c.flatten(), 0, None, None, x, gp.GRB.MINIMIZE)\n",
    "    m.optimize()\n",
    "\n",
    "    # Calculate and save errors\n",
    "    \n",
    "    x_hat_box = x.x\n",
    "    v_hat_box = m.getObjective().getValue()\n",
    "    y_hat_box = y.x\n",
    "    \n",
    "    opt_val_err_box = np.abs(v_star - v_hat_box)\n",
    "    opt_sol_err_box = np.linalg.norm(x_star.flatten() - x_hat_box)\n",
    "    fun_val_err_box = np.abs(y_hat_box - np.linalg.norm(x_hat_box))\n",
    "    feasibi_err_box = np.max([0, np.linalg.norm(x_hat_box) - 1])\n",
    "    \n",
    "    # Add CH validity domain and solve\n",
    "    \n",
    "    u = m.addMVar(shape = (N), name = 'u', lb = 0, ub = 1)\n",
    "    m.addConstr(u.sum() == 1)\n",
    "    m.addConstrs(x[j] == (u @ D_N)[j] for j in range(n1)) \n",
    "    m.optimize()\n",
    "    \n",
    "    # Calculate and save errors\n",
    "    \n",
    "    x_hat_ch = x.x\n",
    "    v_hat_ch = m.getObjective().getValue()\n",
    "    y_hat_ch = y.x\n",
    "    \n",
    "    opt_val_err_ch = np.abs(v_star - v_hat_ch)\n",
    "    opt_sol_err_ch = np.linalg.norm(x_star.flatten() - x_hat_ch)\n",
    "    fun_val_err_ch = np.abs(y_hat_ch - np.linalg.norm(x_hat_ch))\n",
    "    feasibi_err_ch = np.max([0, np.linalg.norm(x_hat_ch) - 1])\n",
    "\n",
    "    # Add CH+ validity domain. We limit the data set to just those, which are feasible\n",
    "    # as suggested by theory\n",
    "\n",
    "    indices_of_infeasible = np.where(h_D_N > 1.0)[0]\n",
    "    if np.shape(indices_of_infeasible)[0] >= N - 4:\n",
    "        print('Uh oh')\n",
    "    \n",
    "    obj = m.getObjective()\n",
    "    f_D_N = np.dot(D_N, c).flatten()\n",
    "    m.addConstr(obj == (u @ f_D_N))\n",
    "    m.addConstr(y == (u @ h_D_N))\n",
    "    m.addConstrs(u[j] == 0 for j in indices_of_infeasible)\n",
    "    m.optimize()\n",
    "    \n",
    "    # Calculate and save errors\n",
    "    \n",
    "    x_hat_chplus = x.x\n",
    "    v_hat_chplus = m.getObjective().getValue()\n",
    "    y_hat_chplus = y.x\n",
    "    \n",
    "    opt_val_err_chplus = np.abs(v_star - v_hat_chplus)\n",
    "    opt_sol_err_chplus = np.linalg.norm(x_star.flatten() - x_hat_chplus)\n",
    "    fun_val_err_chplus = np.abs(y_hat_ch - np.linalg.norm(x_hat_chplus))\n",
    "    feasibi_err_chplus = np.max([0, np.linalg.norm(x_hat_chplus) - 1])\n",
    "    \n",
    "    # Append errors to global data structures\n",
    "    \n",
    "    ove_box    = np.append(ove_box   , opt_val_err_box   )\n",
    "    ove_ch     = np.append(ove_ch    , opt_val_err_ch    )\n",
    "    ove_chplus = np.append(ove_chplus, opt_val_err_chplus)\n",
    "\n",
    "    ose_box    = np.append(ose_box   , opt_sol_err_box   )\n",
    "    ose_ch     = np.append(ose_ch    , opt_sol_err_ch    )\n",
    "    ose_chplus = np.append(ose_chplus, opt_sol_err_chplus)\n",
    "\n",
    "    fve_box    = np.append(fve_box   , fun_val_err_box   )\n",
    "    fve_ch     = np.append(fve_ch    , fun_val_err_ch    )\n",
    "    fve_chplus = np.append(fve_chplus, fun_val_err_chplus)\n",
    "\n",
    "    fe_box    = np.append(fe_box   ,  feasibi_err_box   )\n",
    "    fe_ch     = np.append(fe_ch    ,  feasibi_err_ch    )\n",
    "    fe_chplus = np.append(fe_chplus,  feasibi_err_chplus)\n",
    "\n",
    "# Print final results\n",
    "\n",
    "med_fve = [np.median(fve_box), np.median(fve_ch), np.median(fve_chplus)]\n",
    "med_ose = [np.median(ose_box), np.median(ose_ch), np.median(ose_chplus)]\n",
    "med_ove = [np.median(ove_box), np.median(ove_ch), np.median(ove_chplus)]\n",
    "med_fe = [np.median(fe_box), np.median(fe_ch), np.median(fe_chplus)]\n",
    "\n",
    "#print(med_fve / med_fve[0])\n",
    "#print(med_ove / med_ove[0])\n",
    "#print(med_ose / med_ose[0])\n",
    "#print(med_fe / med_fe[0])\n",
    "\n",
    "tmp1 = med_fve / med_fve[0]\n",
    "tmp1 = np.array(tmp1)[:, np.newaxis]\n",
    "\n",
    "tmp2 = med_ove / med_ove[0]\n",
    "tmp2 = np.array(tmp2)[:, np.newaxis]\n",
    "\n",
    "tmp3 = med_ose / med_ose[0]\n",
    "tmp3 = np.array(tmp3)[:, np.newaxis]\n",
    "\n",
    "tmp4 = med_fe / med_fe[0]\n",
    "tmp4 = np.array(tmp4)[:, np.newaxis]\n",
    "\n",
    "tmp = np.hstack((tmp1, tmp2, tmp3, tmp4))\n",
    "print(tmp)\n",
    "\n",
    "#print('\\n')\n",
    "\n",
    "avg_fve = [np.mean(fve_box), np.mean(fve_ch), np.mean(fve_chplus)]\n",
    "avg_ose = [np.mean(ose_box), np.mean(ose_ch), np.mean(ose_chplus)]\n",
    "avg_ove = [np.mean(ove_box), np.mean(ove_ch), np.mean(ove_chplus)]\n",
    "avg_fe = [np.mean(fe_box), np.mean(fe_ch), np.mean(fe_chplus)]\n",
    "\n",
    "#print(avg_fve / avg_fve[0])\n",
    "#print(avg_ove / avg_ove[0])\n",
    "#print(avg_ose / avg_ose[0])\n",
    "#print(avg_fe / avg_fe[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca050280-afc3-4e26-9b4b-ae9e9fb4a9bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
