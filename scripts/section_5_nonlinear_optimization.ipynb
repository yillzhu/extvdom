{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39c2d36f-5d96-4c87-8d2d-e202e744e878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2597866\n",
      "Academic license - for non-commercial use only - expires 2025-12-10\n",
      "iter = 0\n",
      "Set parameter LogToConsole to value 0\n",
      "Set parameter LogToConsole to value 0\n",
      "Set parameter LogToConsole to value 0\n",
      "Set parameter LogToConsole to value 0\n",
      "Results for n1 = 6\n",
      "\\begin{tabular}{rrrr}\n",
      "\\toprule\n",
      "0 & 1 & 2 & 3 \\\\\n",
      "\\midrule\n",
      "1.000000 & 1.000000 & 1.000000 & 1.000000 \\\\\n",
      "0.792410 & 0.922538 & 0.695346 & 0.792410 \\\\\n",
      "0.931763 & 0.488303 & 1.329890 & 0.931763 \\\\\n",
      "0.207441 & 1.854740 & 1.638082 & 0.000000 \\\\\n",
      "0.354235 & 0.872097 & 1.133830 & 0.013374 \\\\\n",
      "0.585406 & 0.571284 & 0.898179 & 0.278035 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2597866\n",
      "Academic license - for non-commercial use only - expires 2025-12-10\n",
      "iter = 0\n",
      "Set parameter LogToConsole to value 0\n",
      "Set parameter LogToConsole to value 0\n",
      "Set parameter LogToConsole to value 0\n",
      "Set parameter LogToConsole to value 0\n",
      "Results for n1 = 5\n",
      "\\begin{tabular}{rrrr}\n",
      "\\toprule\n",
      "0 & 1 & 2 & 3 \\\\\n",
      "\\midrule\n",
      "1.000000 & 1.000000 & 1.000000 & 1.000000 \\\\\n",
      "1.000000 & 1.000000 & 1.000000 & 1.000000 \\\\\n",
      "0.419342 & 1.234208 & 0.801228 & 0.419342 \\\\\n",
      "0.483073 & 13.013786 & 0.820642 & 0.000000 \\\\\n",
      "0.117674 & 6.354695 & 0.937898 & 0.000000 \\\\\n",
      "0.248414 & 2.351350 & 0.836823 & 0.248414 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import libraries (do we use all of these?)\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import pandas as pd\n",
    "import gurobipy as gp\n",
    "#  import gurobipy_pandas as gppd\n",
    "from gurobi_ml import add_predictor_constr\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "from matplotlib import cm\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from gurobi_helpers import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category = FutureWarning)\n",
    "\n",
    "npr.seed(2023)\n",
    "\n",
    "# Set base dimension\n",
    "\n",
    "for n1 in [10, 5]:\n",
    "\n",
    "    # Set uniform lower and upper bounds for the domain X\n",
    "    \n",
    "    L = -1\n",
    "    U =  1\n",
    "    \n",
    "    # Set sample size\n",
    "    \n",
    "    N = 1000\n",
    "    \n",
    "    # Setup data structures for errors\n",
    "    \n",
    "    ove_box    = np.array([])\n",
    "    ove_ch     = np.array([])\n",
    "    ove_chplus = np.array([])\n",
    "    ove_chp05  = np.array([])\n",
    "    ove_chp1   = np.array([])\n",
    "    ove_if     = np.array([])\n",
    "    \n",
    "    ose_box    = np.array([])\n",
    "    ose_ch     = np.array([])\n",
    "    ose_chplus = np.array([])\n",
    "    ose_chp05  = np.array([])\n",
    "    ose_chp1   = np.array([])\n",
    "    ose_if     = np.array([])\n",
    "    \n",
    "    fve_box    = np.array([])\n",
    "    fve_ch     = np.array([])\n",
    "    fve_chplus = np.array([])\n",
    "    fve_chp05  = np.array([])\n",
    "    fve_chp1   = np.array([])\n",
    "    fve_if     = np.array([])\n",
    "    \n",
    "    fe_box    = np.array([])\n",
    "    fe_ch     = np.array([])\n",
    "    fe_chplus = np.array([])\n",
    "    fe_chp05  = np.array([])\n",
    "    fe_chp1   = np.array([])\n",
    "    fe_if     = np.array([])\n",
    "    \n",
    "    # Initialize optimization environment\n",
    "    \n",
    "    env = gp.Env()\n",
    "    \n",
    "    # Loop over iterations\n",
    "    \n",
    "    for iter in range(100):\n",
    "    \n",
    "        if iter % 1 == 0:\n",
    "            print('iter = ' + str(iter))\n",
    "    \n",
    "        # Generate random linear objective; quadratic part is currently 0\n",
    "    \n",
    "        c = npr.normal(0, 1, [n1, 1])\n",
    "        c = c / np.linalg.norm(c)\n",
    "    \n",
    "        # Determine opt sol and val\n",
    "    \n",
    "        x_star = -c\n",
    "        v_star = -1\n",
    "    \n",
    "        # Generate samples D_N inside and outside of unit ball,\n",
    "        # i.e., not just feasible samples\n",
    "    \n",
    "        #D_N = npr.uniform(L, U, (N, n1))\n",
    "        D_N = npr.normal(0, 1, (N, n1))\n",
    "        for j in range(np.shape(D_N)[0]):\n",
    "            vec = D_N[j, ]\n",
    "            vec = vec.flatten()\n",
    "            vec = vec / np.linalg.norm(vec)\n",
    "            vec = (0.5 + npr.uniform(0, 1)) * vec\n",
    "            D_N[j, ] = vec\n",
    "        \n",
    "        # Evaluate function h on D_N (currently with \"5%\" noise)\n",
    "        \n",
    "        h_D_N = np.linalg.norm(D_N, axis = 1)\n",
    "        h_D_N = h_D_N + 0.05 * npr.normal(0, 1, (N))\n",
    "        # print(\"Reset the noise\")\n",
    "        \n",
    "        # Learn function h_hat\n",
    "        \n",
    "        hidden_size = 30\n",
    "        h_hat = MLPRegressor( \\\n",
    "            hidden_layer_sizes = (hidden_size, hidden_size), max_iter = 1000 \\\n",
    "        )\n",
    "        h_hat = h_hat.fit(D_N, h_D_N)\n",
    "    \n",
    "        # Initialize optimization model\n",
    "    \n",
    "        m = gp.Model(\"trs\", env = env)\n",
    "        m.Params.LogToConsole = 0\n",
    "        m.Params.NonConvex = 2\n",
    "        \n",
    "        # Setup and solve model with Box validity domain\n",
    "        \n",
    "        L_tmp = np.min(D_N, axis = 0)\n",
    "        U_tmp = np.max(D_N, axis = 0)\n",
    "        x = m.addMVar(shape = (n1), name = 'x', lb = L_tmp, ub = U_tmp)\n",
    "        y = m.addVar(name = 'y', ub = 1)\n",
    "        add_predictor_constr(m, h_hat, x, y)\n",
    "        m.setMObjective(None, c.flatten(), 0, None, None, x, gp.GRB.MINIMIZE)\n",
    "        m.optimize()\n",
    "    \n",
    "        # Calculate and save errors\n",
    "        \n",
    "        x_hat_box = x.x\n",
    "        v_hat_box = m.getObjective().getValue()\n",
    "        y_hat_box = y.x\n",
    "        \n",
    "        opt_val_err_box = np.abs(v_star - v_hat_box)\n",
    "        opt_sol_err_box = np.linalg.norm(x_star.flatten() - x_hat_box)\n",
    "        fun_val_err_box = np.abs(y_hat_box - np.linalg.norm(x_hat_box))\n",
    "        feasibi_err_box = np.max([0, np.linalg.norm(x_hat_box) - 1])\n",
    "        \n",
    "        # Add CH validity domain and solve\n",
    "        \n",
    "        u = m.addMVar(shape = (N), name = 'u', lb = 0, ub = 1)\n",
    "        s = m.addMVar(shape=(n1+2), name='s', lb=-gp.GRB.INFINITY)\n",
    "        m.addConstr(u.sum() == 1)\n",
    "        m.addConstrs(x[j] == (u @ D_N)[j] + s[j] for j in range(n1))\n",
    "        epsilon = m.addConstr(s @ s <= (0*np.sqrt(n1))**2)\n",
    "        m.optimize()\n",
    "        \n",
    "        # Calculate and save errors\n",
    "        \n",
    "        x_hat_ch = x.x\n",
    "        v_hat_ch = m.getObjective().getValue()\n",
    "        y_hat_ch = y.x\n",
    "        \n",
    "        opt_val_err_ch = np.abs(v_star - v_hat_ch)\n",
    "        opt_sol_err_ch = np.linalg.norm(x_star.flatten() - x_hat_ch)\n",
    "        fun_val_err_ch = np.abs(y_hat_ch - np.linalg.norm(x_hat_ch))\n",
    "        feasibi_err_ch = np.max([0, np.linalg.norm(x_hat_ch) - 1])\n",
    "    \n",
    "        # Add CH+ validity domain. We limit the data set to just those, which are feasible\n",
    "        # as suggested by theory\n",
    "    \n",
    "        indices_of_infeasible = np.where(h_D_N > 1.0)[0]\n",
    "        if np.shape(indices_of_infeasible)[0] >= N - 4:\n",
    "            print('Uh oh')\n",
    "        \n",
    "        obj = m.getObjective()\n",
    "        f_D_N = np.dot(D_N, c).flatten()\n",
    "        m.addConstr(obj == (u @ f_D_N) + s[-2])\n",
    "        m.addConstr(y == (u @ h_D_N) + s[-1])\n",
    "        m.addConstrs(u[j] == 0 for j in indices_of_infeasible)\n",
    "        m.optimize()\n",
    "        \n",
    "        # Calculate and save errors\n",
    "        \n",
    "        x_hat_chplus = x.x\n",
    "        v_hat_chplus = m.getObjective().getValue()\n",
    "        y_hat_chplus = y.x\n",
    "        \n",
    "        opt_val_err_chplus = np.abs(v_star - v_hat_chplus)\n",
    "        opt_sol_err_chplus = np.linalg.norm(x_star.flatten() - x_hat_chplus)\n",
    "        fun_val_err_chplus = np.abs(y_hat_chplus - np.linalg.norm(x_hat_chplus))\n",
    "        feasibi_err_chplus = np.max([0, np.linalg.norm(x_hat_chplus) - 1])\n",
    "        \n",
    "        # 0.05-CH+\n",
    "        \n",
    "        m.remove(epsilon)\n",
    "        epsilon = m.addConstr(s @ s <= (0.05*np.sqrt(n1))**2)\n",
    "        m.optimize()\n",
    "        \n",
    "        # Calculate and save errors\n",
    "        \n",
    "        x_hat_chp05 = x.x\n",
    "        v_hat_chp05 = m.getObjective().getValue()\n",
    "        y_hat_chp05 = y.x\n",
    "        \n",
    "        opt_val_err_chp05 = np.abs(v_star - v_hat_chp05)\n",
    "        opt_sol_err_chp05 = np.linalg.norm(x_star.flatten() - x_hat_chp05)\n",
    "        fun_val_err_chp05 = np.abs(y_hat_chp05 - np.linalg.norm(x_hat_chp05))\n",
    "        feasibi_err_chp05 = np.max([0, np.linalg.norm(x_hat_chp05) - 1])\n",
    "        \n",
    "        # 0.1-CH+\n",
    "        \n",
    "        m.remove(epsilon)\n",
    "        epsilon = m.addConstr(s @ s <= (0.1*np.sqrt(n1))**2)\n",
    "        m.optimize()\n",
    "        \n",
    "        # Calculate and save errors\n",
    "        \n",
    "        x_hat_chp1 = x.x\n",
    "        v_hat_chp1 = m.getObjective().getValue()\n",
    "        y_hat_chp1 = y.x\n",
    "        \n",
    "        opt_val_err_chp1 = np.abs(v_star - v_hat_chp1)\n",
    "        opt_sol_err_chp1 = np.linalg.norm(x_star.flatten() - x_hat_chp1)\n",
    "        fun_val_err_chp1 = np.abs(y_hat_chp1 - np.linalg.norm(x_hat_chp1))\n",
    "        feasibi_err_chp1 = np.max([0, np.linalg.norm(x_hat_chp1) - 1])\n",
    "\n",
    "        do_isofor = False\n",
    "\n",
    "        if do_isofor:\n",
    "        \n",
    "            # isofor\n",
    "            # Optimize with isolation tree constraint on x\n",
    "                \n",
    "            m = gp.Model(env=env)\n",
    "            m.Params.LogToConsole = 0\n",
    "            m.params.NonConvex = 2\n",
    "        \n",
    "            x = m.addMVar(shape = (n1), name = 'x', lb = L, ub = U)\n",
    "            y = m.addVar(name = 'y', ub = 1)\n",
    "            add_predictor_constr(m, h_hat, x, y)\n",
    "            m.setMObjective(None, c.flatten(), 0, None, None, x, gp.GRB.MINIMIZE)\n",
    "        \n",
    "            scaler = MinMaxScaler()\n",
    "            D_scaled = scaler.fit_transform(D_N)\n",
    "            x_scaled_var = m.addMVar(shape = (n1), name = 'x_scaled', ub=1)\n",
    "            m.addConstr(x_scaled_var == (x-scaler.data_min_)/(scaler.data_max_-scaler.data_min_))\n",
    "            add_isofor_constr(m, X=D_scaled, xx=x_scaled_var, d=5)\n",
    "               \n",
    "            m.optimize()\n",
    "            \n",
    "            # Calculate and save errors\n",
    "            \n",
    "            x_hat_if = x.x\n",
    "            v_hat_if = m.getObjective().getValue()\n",
    "            y_hat_if = y.x\n",
    "            \n",
    "            opt_val_err_if = np.abs(v_star - v_hat_if)\n",
    "            opt_sol_err_if = np.linalg.norm(x_star.flatten() - x_hat_if)\n",
    "            fun_val_err_if = np.abs(y_hat_if - np.linalg.norm(x_hat_if))\n",
    "            feasibi_err_if = np.max([0, np.linalg.norm(x_hat_if) - 1])\n",
    "        \n",
    "        # Append errors to global data structures\n",
    "        \n",
    "        ove_box    = np.append(ove_box   , opt_val_err_box   )\n",
    "        ove_ch     = np.append(ove_ch    , opt_val_err_ch    )\n",
    "        ove_chplus = np.append(ove_chplus, opt_val_err_chplus)\n",
    "        ove_chp05  = np.append(ove_chp05 , opt_val_err_chp05)\n",
    "        ove_chp1   = np.append(ove_chp1  , opt_val_err_chp1)\n",
    "        if do_isofor:\n",
    "            ove_if     = np.append(ove_if    , opt_val_err_if)\n",
    "    \n",
    "        ose_box    = np.append(ose_box   , opt_sol_err_box   )\n",
    "        ose_ch     = np.append(ose_ch    , opt_sol_err_ch    )\n",
    "        ose_chplus = np.append(ose_chplus, opt_sol_err_chplus)\n",
    "        ose_chp05  = np.append(ose_chp05 , opt_sol_err_chp05)\n",
    "        ose_chp1   = np.append(ose_chp1  , opt_sol_err_chp1)\n",
    "        if do_isofor:\n",
    "            ose_if     = np.append(ose_if    , opt_sol_err_if    )\n",
    "    \n",
    "        fve_box    = np.append(fve_box   , fun_val_err_box   )\n",
    "        fve_ch     = np.append(fve_ch    , fun_val_err_ch    )\n",
    "        fve_chplus = np.append(fve_chplus, fun_val_err_chplus)\n",
    "        fve_chp05  = np.append(fve_chp05 , fun_val_err_chp05)\n",
    "        fve_chp1   = np.append(fve_chp1  , fun_val_err_chp1)\n",
    "        if do_isofor:\n",
    "            fve_if     = np.append(fve_if    , fun_val_err_if    )\n",
    "    \n",
    "        fe_box    = np.append(fe_box   ,  feasibi_err_box   )\n",
    "        fe_ch     = np.append(fe_ch    ,  feasibi_err_ch    )\n",
    "        fe_chplus = np.append(fe_chplus,  feasibi_err_chplus)\n",
    "        fe_chp05  = np.append(fe_chp05 ,  feasibi_err_chp05)\n",
    "        fe_chp1   = np.append(fe_chp1  ,  feasibi_err_chp1)\n",
    "        if do_isofor:\n",
    "            fe_if     = np.append(fe_if    ,  feasibi_err_if    )\n",
    "    \n",
    "    # Print final results\n",
    "    \n",
    "    if do_isofor:\n",
    "        med_fve = [np.median(fve_box), np.median(fve_ch), np.median(fve_if), np.median(fve_chplus), np.median(fve_chp05), np.median(fve_chp1)]\n",
    "        med_ose = [np.median(ose_box), np.median(ose_ch), np.median(ose_if), np.median(ose_chplus), np.median(ose_chp05), np.median(ose_chp1)]\n",
    "        med_ove = [np.median(ove_box), np.median(ove_ch), np.median(ove_if), np.median(ove_chplus), np.median(ove_chp05), np.median(ove_chp1)]\n",
    "        med_fe =  [np.median(fe_box) , np.median(fe_ch) , np.median(fe_if) , np.median(fe_chplus) , np.median(fe_chp05) , np.median(fe_chp1) ]\n",
    "    else:\n",
    "        med_fve = [np.median(fve_box), np.median(fve_ch), np.median(fve_chplus), np.median(fve_chp05), np.median(fve_chp1)]\n",
    "        med_ose = [np.median(ose_box), np.median(ose_ch), np.median(ose_chplus), np.median(ose_chp05), np.median(ose_chp1)]\n",
    "        med_ove = [np.median(ove_box), np.median(ove_ch), np.median(ove_chplus), np.median(ove_chp05), np.median(ove_chp1)]\n",
    "        med_fe =  [np.median(fe_box) , np.median(fe_ch) , np.median(fe_chplus) , np.median(fe_chp05) , np.median(fe_chp1) ]\n",
    "    \n",
    "    tmp1 = med_fve / med_fve[0]\n",
    "    tmp1 = np.array(tmp1)[:, np.newaxis]\n",
    "    \n",
    "    tmp2 = med_ove / med_ove[0]\n",
    "    tmp2 = np.array(tmp2)[:, np.newaxis]\n",
    "    \n",
    "    tmp3 = med_ose / med_ose[0]\n",
    "    tmp3 = np.array(tmp3)[:, np.newaxis]\n",
    "    \n",
    "    tmp4 = med_fe / med_fe[0]\n",
    "    tmp4 = np.array(tmp4)[:, np.newaxis]\n",
    "    \n",
    "    tmp = np.hstack((tmp1, tmp2, tmp3, tmp4))\n",
    "\n",
    "    print(\"Results for n1 = \" + str(n1))\n",
    "    \n",
    "    print(pd.DataFrame(tmp).to_latex(index = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c507914-bbd9-4e46-bfbb-8100ac7dd28d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
